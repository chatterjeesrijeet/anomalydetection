## Introduction to Anomaly Detection

This repositoy is having a series of notebooks that is going to cover anomaly detection from scratch to some of the state of the art algorithms. 

_it is still in the progressing phase_

We have an well curated folder structure and we describe teh purpose of each and every folder:

**Data**

External: This is data extracted from third party sources (Immutable data). If no third party data is extracted then this folder is obsolete.

Interim:  In the event external data being available, this data would be the data that we would load for feature engineering by using a script in the src/data directory. This dataset is generated by performing various joins and/or merges to combine the external and raw data.

Processed: This is the data that has been transformed using various machine learning techniques. The features folder that we will get to in the src folder performs various transformations on the data to allow it to be ready for modelling. It serves as a good idea to persist the processed data in order to shorten the training time of our model.

Raw: Having a local subset copy of data ensures that you have a static dataset to perform task on. Additionally, this overcomes any workflow breakdowns due to network latency issues. This data should be considered immutable. If there is no external data then this is the data to be downloaded by the script in src\data.

